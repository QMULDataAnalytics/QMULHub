{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words to vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') #using python2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import preprocess_new as pre\n",
    "import gensim\n",
    "import numpy\n",
    "import csv\n",
    "from nltk.corpus import brown, movie_reviews, treebank\n",
    "from gensim.models import KeyedVectors\n",
    "filename = '/Users/boutrosazar/Downloads/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preProcessedTrainDF = pre.prepareTrainTestSet('train.csv','test.csv','word2vec',seperateLabelInfo=1)#,sampleNum=10) #159548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fff46fc426af1f9a\n"
     ]
    }
   ],
   "source": [
    "#testing the variable\n",
    "print(preProcessedTrainDF.iloc[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the comment and the labels from preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159548\n",
      "159548\n"
     ]
    }
   ],
   "source": [
    "numElements = len(preProcessedTrainDF)\n",
    "myList = []\n",
    "myLabels = []\n",
    "\n",
    "for x in range(numElements):\n",
    "    myList.append(preProcessedTrainDF.iloc[x][1])\n",
    "    myLabels.append([preProcessedTrainDF.iloc[x][i] for i in range(2,8)])\n",
    "\n",
    "\n",
    "print(len(myList))\n",
    "print(len(myLabels))\n",
    "#print(myLabels)\n",
    "\n",
    "#print(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainingList = []\n",
    "\n",
    "# trainingList = list(brown.sents())\n",
    "# trainingList.append(list(movie_reviews.sents()))\n",
    "# trainingList.append(list(treebank.sents()))\n",
    "#trainingList.append(myList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159548\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(iter=1,min_count=0)\n",
    "model.build_vocab(myList)\n",
    "print(model.corpus_count)\n",
    "\n",
    "#model.train(movie_reviews.sents())\n",
    "#model.train(treebank.sents())\n",
    "#model.train(brown.sents(),total_examples=57340,epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the model\n",
    "print(myList[6])\n",
    "print(len(model['piss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the google dataset -> Skip this section if not using google !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(myList, total_words= len(set(myList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.most_similar('bad', topn=5)\n",
    "\n",
    "model.most_similar(positive=['man', 'woman'], negative=['he'])\n",
    "\n",
    "print(myList[2])\n",
    "\n",
    "print(model[','])\n",
    "\n",
    "print(model[myList[2][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159548\n"
     ]
    }
   ],
   "source": [
    "Sent2Vec = []\n",
    "myListLen = len(myList)\n",
    "mySum = numpy.zeros(100)\n",
    "\n",
    "for j in range(myListLen):\n",
    "    mySum = numpy.zeros(100)\n",
    "    for i in myList[j]:\n",
    "        mySum += model[i]\n",
    "    myAvg = mySum/len(myList[j])\n",
    "    Sent2Vec.append([myAvg, myLabels[j]])\n",
    "\n",
    "print(len(Sent2Vec))\n",
    "\n",
    "# Sent2Vec Contains the vector and the labels.\n",
    "#Sent2Vec[6][0] to access the vector\n",
    "#Sent2Vec[6][1] to access the labels\n",
    "#print(Sent2Vec[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to csv File the Sent2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv File contains the sentence as a vector and the labels\n",
    "with open('trainVec.csv', \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerows(Sent2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
